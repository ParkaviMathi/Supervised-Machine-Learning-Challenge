{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the Data\n",
    "\n",
    "The data is located in the Challenge Files Folder:\n",
    "\n",
    "* `lending_data.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the data\n",
    "df = pd.read_csv('Resources/lending_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: loan_status, dtype: int64\n",
      "Data:    loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
      "0    10700.0          7.672            52800        0.431818                5   \n",
      "1     8400.0          6.692            43600        0.311927                3   \n",
      "2     9000.0          6.963            46100        0.349241                3   \n",
      "3    10700.0          7.664            52700        0.430740                5   \n",
      "4    10800.0          7.698            53000        0.433962                5   \n",
      "5    10100.0          7.438            50600        0.407115                4   \n",
      "6    10300.0          7.490            51100        0.412916                4   \n",
      "7     8800.0          6.857            45100        0.334812                3   \n",
      "8     9300.0          7.096            47400        0.367089                3   \n",
      "9     9700.0          7.248            48800        0.385246                4   \n",
      "\n",
      "   derogatory_marks  total_debt  \n",
      "0                 1       22800  \n",
      "1                 0       13600  \n",
      "2                 0       16100  \n",
      "3                 1       22700  \n",
      "4                 1       23000  \n",
      "5                 1       20600  \n",
      "6                 1       21100  \n",
      "7                 0       15100  \n",
      "8                 0       17400  \n",
      "9                 0       18800  \n"
     ]
    }
   ],
   "source": [
    "#Creating the features DataFrame, X, by removing the loan_status column\n",
    "X = df.drop('loan_status', axis=1)\n",
    "#Creating y, the labels set, by using the loan_status column\n",
    "y = df['loan_status']\n",
    "print(f\"Labels: {y[:10]}\")\n",
    "print(f\"Data: {X[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Analysing the difference between the Logistic Regression Model and the Random Forest Classification Model, we can assume that Random Forest Classification Model will have the better performance as:\n",
    "1.The random forest classifier doesnâ€™t face the overfitting issue because it takes the average of all predictions, canceling out the biases and thus, fixing the overfitting problem.\n",
    "2.This algorithm offers you relative feature importance that allows you to select the most contributing features for your classifier easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Fit and Compare Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9921240885954051\n",
      "Testing Data Score: 0.9918489475856377\n"
     ]
    }
   ],
   "source": [
    "# Training a Logistic Regression model and printing the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9975409272252029\n",
      "Testing Score: 0.9917457697069748\n"
     ]
    }
   ],
   "source": [
    "# Training a Random Forest Classifier model and printing the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29066792e-01 2.74137485e-01 1.74521675e-01 1.58682971e-01\n",
      " 1.18902531e-01 8.06639163e-05 1.44607881e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finding the most contributing features\n",
    "features = clf.feature_importances_\n",
    "print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using SelectFromModel function to eliminate the least contributing features to increase efficiency.\n",
    "sel = SelectFromModel(clf)\n",
    "sel.fit(X_train_scaled, y_train)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parka\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9944455908653185\n",
      "Testing Score: 0.9937061494015683\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Scores for scaled X-values using the 'balanced' class-weight hyperparameters\n",
    "clf_1 = LogisticRegression(class_weight='balanced')\n",
    "clf_1.fit(X_selected_train_scaled, y_train)\n",
    "print(f'Training Score: {clf_1.score(X_selected_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf_1.score(X_selected_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9973345714678773\n",
      "Testing Score: 0.9920553033429633\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier Scores for scaled X-values using the 'balanced' class-weight hyperparameters\n",
    "clf_2 = RandomForestClassifier(class_weight='balanced')\n",
    "clf_2.fit(X_selected_train_scaled, y_train)\n",
    "print(f'Training Score: {clf_2.score(X_selected_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf_2.score(X_selected_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "From the Traing and Test scores of both the Models we can see that Logistic Regression has better effeciency. \n",
    "This has made our assumption incorrect as Logistic Regression Model can also be trained to improve the performance by eliminating the least performing features in our dataset and scaling the values to avoid overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
